{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "from featuresextraction import *\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpq(img,winSize=3,freqestim=1,mode='nh'):\n",
    "    rho=0.90\n",
    "\n",
    "    STFTalpha=1/winSize  # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "    sigmaS=(winSize-1)/4 # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "    sigmaA=8/(winSize-1) # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "\n",
    "    convmode='valid' # Compute descriptor responses only on part that have full neigborhood. Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "\n",
    "    img=np.float64(img) # Convert np.image to double\n",
    "    r=(winSize-1)/2 # Get radius from window size\n",
    "    x=np.arange(-r,r+1)[np.newaxis] # Form spatial coordinates in window\n",
    "\n",
    "    if freqestim==1:  #  STFT uniform window\n",
    "        #  Basic STFT filters\n",
    "        w0=np.ones_like(x)\n",
    "        w1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "        w2=np.conj(w1)\n",
    "\n",
    "    ## Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "    # Run first filter\n",
    "    filterResp1=convolve2d(convolve2d(img,w0.T,convmode),w1,convmode)\n",
    "    filterResp2=convolve2d(convolve2d(img,w1.T,convmode),w0,convmode)\n",
    "    filterResp3=convolve2d(convolve2d(img,w1.T,convmode),w1,convmode)\n",
    "    filterResp4=convolve2d(convolve2d(img,w1.T,convmode),w2,convmode)\n",
    "\n",
    "    # Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "    freqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                        filterResp2.real, filterResp2.imag,\n",
    "                        filterResp3.real, filterResp3.imag,\n",
    "                        filterResp4.real, filterResp4.imag])\n",
    "\n",
    "    ## Perform quantization and compute LPQ codewords\n",
    "    inds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "    LPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "    ## Switch format to uint8 if LPQ code np.image is required as output\n",
    "    if mode=='im':\n",
    "        LPQdesc=np.uint8(LPQdesc)\n",
    "\n",
    "    ## Histogram if needed\n",
    "    if mode=='nh' or mode=='h':\n",
    "        LPQdesc=np.histogram(LPQdesc.flatten(),range(256))[0]\n",
    "\n",
    "    ## Normalize histogram if needed\n",
    "    if mode=='nh':\n",
    "        LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "\n",
    "    return LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3583: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:185: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "HVSL_feature = []\n",
    "LVL_features = []\n",
    "HPP_features = []\n",
    "TOS_features = []\n",
    "Stats_features = []\n",
    "TH_features = []\n",
    "lpq_features = []\n",
    "labels = []\n",
    "feature_to_plot = []\n",
    "for i in range(1, 10):\n",
    "    input_dir = f'ACdata_base/{i}/'\n",
    "    dirs = os.listdir(input_dir)\n",
    "    for idx,img_dir in enumerate(dirs):\n",
    "        #print(\"processing img \"+str(img_dir))\n",
    "        pre = img_dir.split('.')[0]\n",
    "        img_dir = input_dir + img_dir\n",
    "        img_rgb = cv2.imread(img_dir)\n",
    "        img = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        binarizedImg =  Binarize_Histogram(img,pre)\n",
    "\n",
    "        ####preprocessing for feature extraction:\n",
    "        ####our skeletonization\n",
    "        skeletonized = Skeletonization(binarizedImg, pre)\n",
    "\n",
    "        ###their skeletonization\n",
    "        skeleton = 255 - skeletonize(1-binarizedImg/255)*255\n",
    "        ####edge detection:\n",
    "        edged = LaplacianEdge(binarizedImg, pre)\n",
    "        \n",
    "        LVL_descriptor = getLVL(skeletonized,img,pre)\n",
    "        HVSL_decriptor = getHVSL(edged,img_rgb,pre) #contains 2 features (V/H,(#of black pixels/((H/total)+(V/total))))\n",
    "        HPP_descriptor = getHPP(cropToText(binarizedImg),pre)\n",
    "        TOS_descriptor = getTOS(img)\n",
    "        Stats_descriptor = getStatsFeatures(binarizedImg)\n",
    "        lpq_decriptor= lpq(binarizedImg)\n",
    "\n",
    "        lpq_features.append(lpq_decriptor)\n",
    "        HVSL_feature.append(HVSL_decriptor)\n",
    "        LVL_features.append(LVL_descriptor)\n",
    "        HPP_features.append(HPP_descriptor)\n",
    "        TOS_features.append(TOS_descriptor)\n",
    "        Stats_features.append(Stats_descriptor)\n",
    "        #TH_features.append(TH_descriptor)\n",
    "        labels.append([i])\n",
    "\n",
    "#######classifier\n",
    "labels = np.array(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(lpq_features, labels, test_size=0.25, random_state=10, stratify=labels)\n",
    "clf = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(500,250),random_state=1,solver='lbfgs',max_iter=10000)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "predicted_lpq = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(HVSL_feature, labels, test_size=0.25,random_state=10, stratify=labels)\n",
    "clf_HVSL = svm.SVC(probability=True)\n",
    "clf_HVSL.fit(X_train, y_train)\n",
    "predicted_HVSL = clf_HVSL.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(HPP_features, labels, test_size=0.25,random_state=10, stratify=labels)\n",
    "clf_HPP = svm.SVC(probability=True)\n",
    "clf_HPP.fit(X_train, y_train)\n",
    "predicted_HPP = clf_HPP.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Stats_features, labels, test_size=0.25,random_state=10, stratify=labels)\n",
    "clf_Stats = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(9,18),random_state=1,solver='lbfgs',max_iter=10000,)\n",
    "clf_Stats.fit(X_train,y_train)\n",
    "predicted_Stats = clf_Stats.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(TOS_features, labels, test_size=0.25,random_state=10, stratify=labels)\n",
    "clf_TOS = svm.SVC(probability=True) \n",
    "clf_TOS.fit(X_train,y_train)\n",
    "predicted_TOS = clf_TOS.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(LVL_features, labels, test_size=0.25,random_state=10, stratify=labels)\n",
    "clf_LVL = svm.SVC(probability=True)\n",
    "clf_LVL.fit(X_train,y_train)\n",
    "predicted_LVL = clf_LVL.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = predicted_HPP + predicted_HVSL + predicted_TOS + predicted_Stats + predicted_LVL+ predicted_lpq\n",
    "predicted = np.argmax(summation, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      1.00      0.99        48\n",
      "           2       0.98      1.00      0.99        48\n",
      "           3       0.93      0.93      0.93        45\n",
      "           4       0.98      0.93      0.96        46\n",
      "           5       1.00      0.98      0.99        49\n",
      "           6       1.00      0.98      0.99        45\n",
      "           7       0.98      1.00      0.99        46\n",
      "           8       0.98      1.00      0.99        47\n",
      "           9       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           0.98       422\n",
      "   macro avg       0.98      0.98      0.98       422\n",
      "weighted avg       0.98      0.98      0.98       422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_lpq3 = np.argmax(predicted_lpq, axis=1)+1\n",
    "# # print(predicted.shape)\n",
    "# accuracy_test = np.mean(y_test.flatten()==predicted_lpq) * 100\n",
    "# print(accuracy_test)\n",
    "predicted_lpq2 = clf.predict(x_test)\n",
    "print(\n",
    "    #f\"Classification report for classifier {voting_clf}:\\n\"\n",
    "    f\"{classification_report(y_test, predicted)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3583: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:185: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "E:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "HVSL_test = []\n",
    "LVL_test = []\n",
    "HPP_test = []\n",
    "TOS_test = []\n",
    "Stats_test = []\n",
    "lpq_test = []\n",
    "labels_test = []\n",
    "for i in range(1, 10):\n",
    "    input_dir = f'test_set_v2/{i}/'\n",
    "    dirs = os.listdir(input_dir)\n",
    "    for idx,img_dir in enumerate(dirs):\n",
    "        #print(\"processing img \"+str(img_dir))\n",
    "        pre = img_dir.split('.')[0]\n",
    "        img_dir = input_dir + img_dir\n",
    "        img_rgb = cv2.imread(img_dir)\n",
    "        img = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        binarizedImg =  Binarize_Histogram(img,pre)\n",
    "\n",
    "        ####preprocessing for feature extraction:\n",
    "        ####our skeletonization\n",
    "        skeletonized = Skeletonization(binarizedImg, pre)\n",
    "\n",
    "        ###their skeletonization\n",
    "        skeleton = 255 - skeletonize(1-binarizedImg/255)*255\n",
    "        ####edge detection:\n",
    "        edged = LaplacianEdge(binarizedImg, pre)\n",
    "        \n",
    "        LVL_descriptor = getLVL(skeletonized,img,pre)\n",
    "        HVSL_decriptor = getHVSL(edged,img_rgb,pre) #contains 2 features (V/H,(#of black pixels/((H/total)+(V/total))))\n",
    "        HPP_descriptor = getHPP(cropToText(binarizedImg),pre)\n",
    "        TOS_descriptor = getTOS(img)\n",
    "        Stats_descriptor = getStatsFeatures(binarizedImg)\n",
    "        lpq_decriptor= lpq(binarizedImg)\n",
    "\n",
    "        lpq_test.append(lpq_decriptor)\n",
    "        HVSL_test.append(HVSL_decriptor)\n",
    "        LVL_test.append(LVL_descriptor)\n",
    "        HPP_test.append(HPP_descriptor)\n",
    "        TOS_test.append(TOS_descriptor)\n",
    "        Stats_test.append(Stats_descriptor)\n",
    "        labels_test.append([i])\n",
    "\n",
    "\n",
    "\n",
    "#######classifier\n",
    "labels_test = np.array(labels_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.46      0.63        13\n",
      "           2       1.00      0.09      0.17        11\n",
      "           3       0.83      0.45      0.59        11\n",
      "           4       0.53      0.91      0.67        11\n",
      "           5       0.50      0.90      0.64        10\n",
      "           6       0.50      1.00      0.67        10\n",
      "           7       1.00      0.78      0.88         9\n",
      "           8       1.00      0.44      0.62         9\n",
      "           9       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.67        96\n",
      "   macro avg       0.80      0.67      0.64        96\n",
      "weighted avg       0.80      0.67      0.64        96\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####testing:\n",
    "predicted_lpq_test = clf.predict_proba(lpq_test)\n",
    "predicted_HVSL_test = clf_HVSL.predict_proba(HVSL_test)\n",
    "predicted_HPP_test = clf_HPP.predict_proba(HPP_test)\n",
    "predicted_Stats_test = clf_Stats.predict_proba(Stats_test)\n",
    "predicted_TOS_test = clf_TOS.predict_proba(TOS_test)\n",
    "predicted_LVL_test = clf_LVL.predict_proba(LVL_test)\n",
    "\n",
    "summation_test =  predicted_lpq_test + predicted_HPP_test + predicted_LVL_test + predicted_TOS_test + predicted_Stats_test\n",
    "predicted_test = np.argmax(summation_test, axis=1) + 1\n",
    "\n",
    "print(\n",
    "    #f\"Classification report for classifier {voting_clf}:\\n\"\n",
    "    f\"{classification_report(labels_test, predicted_test)}\\n\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
