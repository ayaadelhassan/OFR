{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "from skimage.morphology import skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x, y, x1, y1):\n",
    "    return ((x - x1)**2)**(0.5) + ((y - y1)**2) ** (0.5)\n",
    "\n",
    "def getThicknessHist(skeleton,binarizedImg):\n",
    "    blackPixelsSk = np.where(skeleton==0)\n",
    "    contours,_ = cv2.findContours(255-binarizedImg, cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_NONE)\n",
    "    boundindBoxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    thick_arr = []\n",
    "    for i in range(0,len(blackPixelsSk[0]),3):\n",
    "        y,x = blackPixelsSk[0][i],blackPixelsSk[1][i]\n",
    "\n",
    "        for idx,(xB,yB,wB,hB) in enumerate(boundindBoxes):\n",
    "            if y>=yB and x>=xB and y<=(yB+hB) and x<=(xB+wB):\n",
    "                insideContour = contours[idx] \n",
    "                break\n",
    "\n",
    "        insideContour = insideContour.T\n",
    "\n",
    "        cols= insideContour[0][0]\n",
    "        rows= insideContour[1][0]\n",
    "        idxs = list(range(len(rows)))\n",
    "        abovePoints = []\n",
    "        belowPoints = []\n",
    "        rightPoints = []\n",
    "        leftPoints =  []\n",
    "        \n",
    "        for i,r,c in zip(idxs,rows,cols):\n",
    "            if r<y and c==x:\n",
    "                abovePoints.append(i)\n",
    "            elif  r>y and c==x:\n",
    "                belowPoints.append(i)\n",
    "            elif r==y and c>x:\n",
    "                rightPoints.append(i)\n",
    "            elif r==y and c<x:\n",
    "                leftPoints.append(i)\n",
    "                \n",
    "        if len(belowPoints):\n",
    "            minIdx = np.argmin([dist(x,y,cols[belowPoints[i]],rows[belowPoints[i]]) for i in range(len(belowPoints))])\n",
    "            nearBelow = rows[belowPoints[minIdx]],cols[belowPoints[minIdx]] \n",
    "        else: nearBelow = y,x\n",
    "\n",
    "        if len(abovePoints):\n",
    "            minIdx = np.argmin([dist(x,y,cols[abovePoints[i]],rows[abovePoints[i]]) for i in range(len(abovePoints))])\n",
    "            nearAbove = rows[abovePoints[minIdx]],cols[abovePoints[minIdx]] \n",
    "        else: nearAbove = y,x\n",
    "\n",
    "        if len(rightPoints): \n",
    "            minIdx = np.argmin([dist(x,y,cols[rightPoints[i]],rows[rightPoints[i]]) for i in range(len(rightPoints))])\n",
    "            nearRight = rows[rightPoints[minIdx]],cols[rightPoints[minIdx]] \n",
    "        else: nearRight = y,x\n",
    "\n",
    "        if len(leftPoints): \n",
    "            minIdx = np.argmin([dist(x,y,cols[leftPoints[i]],rows[leftPoints[i]]) for i in range(len(leftPoints))])\n",
    "            nearLeft = rows[leftPoints[minIdx]],cols[leftPoints[minIdx]] \n",
    "        else: nearLeft = y,x\n",
    "            \n",
    "        distVer = dist(nearBelow[1],nearBelow[0],nearAbove[1],nearAbove[0])\n",
    "        distHor = dist(nearRight[1],nearRight[0],nearLeft[1],nearLeft[0])\n",
    "        thickness = min(distVer,distHor)\n",
    "        thick_arr.append(thickness)\n",
    "    thick_hist,bins = np.histogram(thick_arr, 10)\n",
    "    return list(thick_hist),list(bins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_NN(X,Y):\n",
    "    print(\"Start Training \")\n",
    "    N = len(X[0])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=4, stratify=Y)\n",
    "    clf = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(32,16),random_state=1,solver='lbfgs',max_iter=10000)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(\"Finished Fitting\")\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    accuracy_test = np.mean(y_test==y_pred_test) * 100\n",
    "    \n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    accuracy_train = np.mean(y_train==y_pred_train) * 100\n",
    "    return accuracy_train,accuracy_test,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curFont 8\n",
      "0 190\n",
      "1 190\n",
      "2 190\n",
      "3 190\n",
      "4 190\n",
      "5 190\n",
      "6 190\n",
      "7 190\n",
      "8 190\n",
      "9 190\n",
      "10 190\n",
      "11 190\n",
      "12 190\n",
      "13 190\n",
      "14 190\n",
      "15 190\n",
      "16 190\n",
      "17 190\n",
      "18 190\n",
      "19 190\n",
      "20 190\n",
      "21 190\n",
      "22 190\n",
      "23 190\n",
      "24 190\n",
      "25 190\n",
      "26 190\n",
      "27 190\n",
      "28 190\n",
      "29 190\n",
      "30 190\n",
      "31 190\n",
      "32 190\n",
      "33 190\n",
      "34 190\n",
      "35 190\n",
      "36 190\n",
      "37 190\n",
      "38 190\n",
      "39 190\n",
      "40 190\n",
      "41 190\n",
      "42 190\n",
      "43 190\n",
      "44 190\n",
      "45 190\n",
      "46 190\n",
      "47 190\n",
      "48 190\n",
      "49 190\n",
      "50 190\n",
      "51 190\n",
      "52 190\n",
      "53 190\n",
      "54 190\n",
      "55 190\n",
      "56 190\n",
      "57 190\n",
      "58 190\n",
      "59 190\n",
      "60 190\n",
      "61 190\n",
      "62 190\n",
      "63 190\n",
      "64 190\n",
      "65 190\n",
      "66 190\n",
      "67 190\n",
      "68 190\n",
      "69 190\n",
      "70 190\n",
      "71 190\n",
      "72 190\n",
      "73 190\n",
      "74 190\n",
      "75 190\n",
      "76 190\n",
      "77 190\n",
      "78 190\n",
      "79 190\n",
      "80 190\n",
      "81 190\n",
      "82 190\n",
      "83 190\n",
      "84 190\n",
      "85 190\n",
      "86 190\n",
      "87 190\n",
      "88 190\n",
      "89 190\n",
      "90 190\n",
      "91 190\n",
      "92 190\n",
      "93 190\n",
      "94 190\n",
      "95 190\n",
      "96 190\n",
      "97 190\n",
      "98 190\n",
      "99 190\n",
      "100 190\n",
      "101 190\n",
      "102 190\n",
      "103 190\n",
      "104 190\n",
      "105 190\n",
      "106 190\n",
      "107 190\n",
      "108 190\n",
      "109 190\n",
      "110 190\n",
      "111 190\n",
      "112 190\n",
      "113 190\n",
      "114 190\n",
      "115 190\n",
      "116 190\n",
      "117 190\n",
      "118 190\n",
      "119 190\n",
      "120 190\n",
      "121 190\n",
      "122 190\n",
      "123 190\n",
      "124 190\n",
      "125 190\n",
      "126 190\n",
      "127 190\n",
      "128 190\n",
      "129 190\n",
      "130 190\n",
      "131 190\n",
      "132 190\n",
      "133 190\n",
      "134 190\n",
      "135 190\n",
      "136 190\n",
      "137 190\n",
      "138 190\n",
      "139 190\n",
      "140 190\n",
      "141 190\n",
      "142 190\n",
      "143 190\n",
      "144 190\n",
      "145 190\n",
      "146 190\n",
      "147 190\n",
      "148 190\n",
      "149 190\n",
      "150 190\n",
      "151 190\n",
      "152 190\n",
      "153 190\n",
      "154 190\n",
      "155 190\n",
      "156 190\n",
      "157 190\n",
      "158 190\n",
      "159 190\n",
      "160 190\n",
      "161 190\n",
      "162 190\n",
      "163 190\n",
      "164 190\n",
      "165 190\n",
      "166 190\n",
      "167 190\n",
      "168 190\n",
      "169 190\n",
      "170 190\n",
      "171 190\n",
      "172 190\n",
      "173 190\n",
      "174 190\n",
      "175 190\n",
      "176 190\n",
      "177 190\n",
      "178 190\n",
      "179 190\n",
      "180 190\n",
      "181 190\n",
      "182 190\n",
      "183 190\n",
      "184 190\n",
      "185 190\n",
      "186 190\n",
      "187 190\n",
      "188 190\n",
      "189 190\n",
      "curFont 5\n",
      "0 195\n",
      "1 195\n",
      "2 195\n",
      "3 195\n",
      "4 195\n",
      "5 195\n",
      "6 195\n",
      "7 195\n",
      "8 195\n",
      "9 195\n",
      "10 195\n",
      "11 195\n",
      "12 195\n",
      "13 195\n",
      "14 195\n",
      "15 195\n",
      "16 195\n",
      "17 195\n",
      "18 195\n",
      "19 195\n",
      "20 195\n",
      "21 195\n",
      "22 195\n",
      "23 195\n",
      "24 195\n",
      "25 195\n",
      "26 195\n",
      "27 195\n",
      "28 195\n",
      "29 195\n",
      "30 195\n",
      "31 195\n",
      "32 195\n",
      "33 195\n",
      "34 195\n",
      "35 195\n",
      "36 195\n",
      "37 195\n",
      "38 195\n",
      "39 195\n",
      "40 195\n",
      "41 195\n",
      "42 195\n",
      "43 195\n",
      "44 195\n",
      "45 195\n",
      "46 195\n",
      "47 195\n",
      "48 195\n",
      "49 195\n",
      "50 195\n",
      "51 195\n",
      "52 195\n",
      "53 195\n",
      "54 195\n",
      "55 195\n",
      "56 195\n",
      "57 195\n",
      "58 195\n",
      "59 195\n",
      "60 195\n",
      "61 195\n",
      "62 195\n",
      "63 195\n",
      "64 195\n",
      "65 195\n",
      "66 195\n",
      "67 195\n",
      "68 195\n",
      "69 195\n",
      "70 195\n",
      "71 195\n",
      "72 195\n",
      "73 195\n",
      "74 195\n",
      "75 195\n",
      "76 195\n",
      "77 195\n",
      "78 195\n",
      "79 195\n",
      "80 195\n",
      "81 195\n",
      "82 195\n",
      "83 195\n",
      "84 195\n",
      "85 195\n",
      "86 195\n",
      "87 195\n",
      "88 195\n",
      "89 195\n",
      "90 195\n",
      "91 195\n",
      "92 195\n",
      "93 195\n",
      "94 195\n",
      "95 195\n",
      "96 195\n",
      "97 195\n",
      "98 195\n",
      "99 195\n",
      "100 195\n",
      "101 195\n",
      "102 195\n",
      "103 195\n",
      "104 195\n",
      "105 195\n",
      "106 195\n",
      "107 195\n",
      "108 195\n",
      "109 195\n",
      "110 195\n",
      "111 195\n",
      "112 195\n",
      "113 195\n",
      "114 195\n",
      "115 195\n",
      "116 195\n",
      "117 195\n",
      "118 195\n",
      "119 195\n",
      "120 195\n",
      "121 195\n",
      "122 195\n",
      "123 195\n",
      "124 195\n",
      "125 195\n",
      "126 195\n",
      "127 195\n",
      "128 195\n",
      "129 195\n",
      "130 195\n",
      "131 195\n",
      "132 195\n",
      "133 195\n",
      "134 195\n",
      "135 195\n",
      "136 195\n",
      "137 195\n",
      "138 195\n",
      "139 195\n",
      "140 195\n",
      "141 195\n",
      "142 195\n",
      "143 195\n",
      "144 195\n",
      "145 195\n",
      "146 195\n",
      "147 195\n",
      "148 195\n",
      "149 195\n",
      "150 195\n",
      "151 195\n",
      "152 195\n",
      "153 195\n",
      "154 195\n",
      "155 195\n",
      "156 195\n",
      "157 195\n",
      "158 195\n",
      "159 195\n",
      "160 195\n",
      "161 195\n",
      "162 195\n",
      "163 195\n",
      "164 195\n",
      "165 195\n",
      "166 195\n",
      "167 195\n",
      "168 195\n",
      "169 195\n",
      "170 195\n",
      "171 195\n",
      "172 195\n",
      "173 195\n",
      "174 195\n",
      "175 195\n",
      "176 195\n",
      "177 195\n",
      "178 195\n",
      "179 195\n",
      "180 195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir='ACdata_base/'\n",
    "\n",
    "fonts = os.listdir(base_dir)\n",
    "X,Y=[],[]\n",
    "for font in fonts:\n",
    "    h,w = 0,0\n",
    "    data = os.listdir(base_dir+font)\n",
    "    print(\"curFont\",font)\n",
    "    for i,img in enumerate(data):\n",
    "        img_dir = base_dir+font+'/'+img\n",
    "        imgGray = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "        imgGray = (resize(imgGray, (110, 200))*255).astype(np.uint8)\n",
    "        binarizedImg =  Binarize_Histogram(imgGray,'')\n",
    "        skeleton = 255 - skeletonize(1-binarizedImg/255)*255\n",
    "        hist,bins = getThicknessHist(skeleton,binarizedImg)\n",
    "        features = hist + bins\n",
    "        print(i,len(data))\n",
    "        X.append(features)\n",
    "        Y.append(int(font))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyTrain,accuracyTest,ModelNN = Train_NN(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGray = cv2.imread('1498.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "binarizedImg =  Binarize_Histogram(imgGray,'')\n",
    "skeleton = 255 - skeletonize(1-binarizedImg/255)*255\n",
    "hist,bins = getThicknessHist(skeleton,binarizedImg)\n",
    "plt.hist(bins[:-1], bins, weights=hist)\n",
    "print(hist)\n",
    "print(bins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
